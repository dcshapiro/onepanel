{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load profit/loss data\n",
    "profits_tbl = pd.read_csv('stock_profits2.csv')\n",
    "\n",
    "#load embedding CNN model\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "#load list of all images\n",
    "fileList = glob.glob(\"faces/*/*.jpg\")\n",
    "\n",
    "counter=0\n",
    "#run through the images and create dataframe of embeddings and profit/loss\n",
    "for img_path in fileList:\n",
    "    try:\n",
    "        counter+=1\n",
    "        folder = img_path.split(\"/\")[1]\n",
    "        searchTerms = [\"CEO\",\"ChiefExecutiveOfficer\",\"CEOprofilephoto\",\"topexecutive\",\"profilephoto\"]\n",
    "        for term in searchTerms:\n",
    "            folder=folder.replace(term,\"\")\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        fc1 = model.predict(x)\n",
    "        embedding = fc1[0]\n",
    "        ticker = folder\n",
    "        \n",
    "        parray = profits_tbl.loc[profits_tbl['Symbol'] == ticker][\"Profit\"]\n",
    "        profit=int(parray)\n",
    "        \n",
    "        \n",
    "        with open(\"embeddings.csv\", \"a\") as f:\n",
    "            row = pd.DataFrame([ticker, profit, img_path] + list(embedding)).T\n",
    "            row.to_csv(f, header=False, index=False)\n",
    "        \n",
    "        if counter % 100 ==1:\n",
    "            print(len(fileList),\"tasks\",counter,\"done\",100*round(counter/float(len(fileList)),3),\"%\")\n",
    "#             print(ticker,profit,img_path,embedding)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_frame = pd.read_csv('embeddings.csv', header=None)\n",
    "print(profit_frame.shape)\n",
    "## ticker, profit, filename, <embedding.....>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(profit_frame.iloc[:,3:])\n",
    "y = np.array(profit_frame.iloc[:,1])\n",
    "print(X[:3], X.shape)\n",
    "print(y[:3], y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=128, \n",
    "          class_weight=class_weights)\n",
    "score = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(np.around(model.predict(X_test), decimals=0))\n",
    "true = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare = pd.concat([predicted, true], axis=1)\n",
    "compare.columns = ['predicted', 'actual_profit']\n",
    "compare['true positive'] = compare['predicted'] * compare['actual_profit']\n",
    "compare['true negative'] = (1 - compare['predicted']) * (1 - compare['actual_profit'])\n",
    "compare['false positive'] = compare['predicted'] * (1 - compare['actual_profit'])\n",
    "compare['false negative'] = (1 - compare['predicted']) * compare['actual_profit']\n",
    "display(compare[:10])\n",
    "print(compare.sum()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
